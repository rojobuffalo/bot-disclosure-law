# Bot Disclosure Law

This is an idea for a law that should exist to protect humans: a law that requires all bots to be labeled as bots. Bot activity should always be labeled so that humans can easily distinguish it from human activity. Any service which stores user accounts, must ensure that any account owned or accessed by a bot program must have a user name that ends in 'bot'. All messages, comments, and audio clips must be labeled with the bot name. User activity statistics like views, upvotes, downvotes, and retweets must clearly designate the portion that is bots or not include bot activity in those statistics. Generative art, music, and videos must be clearly attributed with the bot name.

## Terminology

- Bot: a program that acts like a human; a program that could be mistaken for a human or human behavior  
- Label: a registered user name that ends in 'bot' and is displayed at all times  
- Activity: something a human does that a bot may also do, including:
  - Natural language text
  - Natural language voice
  - Gaming
  - Video views
  - Upvotes
  - Downvotes
  - Retweets
  - Generative art
  - Auction bidding

## Justification

Humans spend a lot of time these days accessing information and networks with many other humans who they do not know personally. In many cases it is difficult or impossible to tell if user activity is from real people or bot programs. Bot programs can be scaled up almost without limit, which means our communication networks and normal human intuitions about other humans in our communities are vulnerable to a new kind of manipulation.

## Detecting violations

Detecting bots which are acting like people is not easy and will likely get more difficult as we advance into the future. Companies already implement terms of service agreements and monitor for violations. Strategies for monitoring and moderating content vary widely.

**TODO: elaborate on common strategies for detecting TOS violations**  
**TODO: expand on domain-specific strategies for detecting bots**

## Exceptions

There are times when someone may want to subject themself to **willful blindness**. For instance, a participant in a Turing test would want to not know before hand whether they were talking to a bot or human. An exception waiver might be a good idea for such cases. However, these waivers should be for specific interactions or events and not for things like general user agreements that apply for an extended duration.

## Determing guilty parties

**TODO**

## Corrections and penalties

Any bot that is proven to be acting without an appropriate label should be immediately shut down. Humans who may have been affected should be notified of the mislabeled activity.

**TODO: expand on possible penalities**
